{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Time series forecasting\n",
    "> By _*Alpha Olomi*_ [<hello@alphaolomi.com>](mailto:hello@alphaolomi.com)\n",
    "> Date: 2019 08 25\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Time series forecasting is a process, and the only way to get good forecasts is to practice this process.\n",
    "\n",
    "In this tutorial, you will discover how to forecast the monthly sales of French champagne with Python.\n",
    "\n",
    "Working through this tutorial will provide you with a framework for the steps and the tools for working through your own time series forecasting problems.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "- How to confirm your Python environment and carefully define a time series forecasting problem.\n",
    "- How to create a test harness for evaluating models, develop a baseline forecast, and better understand your problem with the tools of time series analysis.\n",
    "- How to develop an autoregressive integrated moving average model, save it to file, and later load it to make predictions for new time steps.\n",
    "\n",
    "Let’s get started.\n",
    "\n",
    "\n",
    "## Overview\n",
    "In this tutorial, we will work through a time series forecasting project from end-to-end, from downloading the dataset and defining the problem to training a final model and making predictions.\n",
    "\n",
    "This project is not exhaustive, but shows how you can get good results quickly by working through a time series forecasting problem systematically.\n",
    "\n",
    "The steps of this project that we will through are as follows.\n",
    "\n",
    "- Environment.\n",
    "- Problem Description.\n",
    "- Test Harness.\n",
    "- Persistence.\n",
    "- Data Analysis.\n",
    "- ARIMA Models.\n",
    "- Model Validation.\n",
    "\n",
    "This will provide a template for working through a time series prediction problem that you can use on your own dataset.\n",
    "\n",
    "\n",
    "\n",
    "1. Environment\n",
    "This tutorial assumes an installed and working SciPy environment and dependencies, including:\n",
    "\n",
    "- SciPy\n",
    "- NumPy\n",
    "- Matplotlib\n",
    "- Pandas\n",
    "- scikit-learn\n",
    "- statsmodels\n",
    "\n",
    "If you need help installing Python and the SciPy environment on your workstation, consider the Anaconda distribution that manages much of it for you.\n",
    "\n",
    "This script will help you check your installed versions of these libraries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scipy\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)\n",
    "# statsmodels\n",
    "import statsmodels\n",
    "print('statsmodels: %s' % statsmodels.__version__)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Problem Description\n",
    "The problem is to predict the number of monthly sales of champagne for the Perrin Freres label (named for a region in France).\n",
    "\n",
    "The dataset provides the number of monthly sales of champagne from January 1964 to September 1972, or just under 10 years of data.\n",
    "\n",
    "The values are a count of millions of sales and there are 105 observations.\n",
    "\n",
    "The dataset is credited to Makridakis and Wheelwright, 1989.\n",
    "\n",
    "Download the dataset.\n",
    "Download the dataset as a CSV file and place it in your current working directory with the filename “champagne.csv“.\n",
    "\n",
    "## 3. Test Harness\n",
    "We must develop a test harness to investigate the data and evaluate candidate models.\n",
    "\n",
    "This involves two steps:\n",
    "\n",
    "- Defining a Validation Dataset.\n",
    "- Developing a Method for Model Evaluation.\n",
    "\n",
    "## 3.1 Validation Dataset\n",
    "The dataset is not current. This means that we cannot easily collect updated data to validate the model.\n",
    "\n",
    "Therefore we will pretend that it is September 1971 and withhold the last one year of data from analysis and model selection.\n",
    "\n",
    "This final year of data will be used to validate the final model.\n",
    "\n",
    "The code below will load the dataset as a Pandas Series and split into two, one for model development (dataset.csv) and the other for validation (validation.csv)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "series = Series.from_csv('champagne.csv', header=0)\n",
    "split_point = len(series) - 12\n",
    "dataset, validation = series[0:split_point], series[split_point:]\n",
    "print('Dataset %d, Validation %d' % (len(dataset), len(validation)))\n",
    "dataset.to_csv('dataset.csv')\n",
    "validation.to_csv('validation.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example creates two files and prints the number of observations in each.\n",
    "\n",
    "The specific contents of these files are:\n",
    "\n",
    "- dataset.csv: Observations from January 1964 to September 1971 (93 observations)\n",
    "- validation.csv: Observations from October 1971 to September 1972 (12 observations)\n",
    "\n",
    "The validation dataset is about 11% of the original dataset.\n",
    "\n",
    "> Note that the saved datasets do not have a header line, therefore we do not need to cater for this when working with these files later.\n",
    "\n",
    "## 3.2. Model Evaluation\n",
    "Model evaluation will only be performed on the data in dataset.csv prepared in the previous section.\n",
    "\n",
    "Model evaluation involves two elements:\n",
    "\n",
    "- Performance Measure.\n",
    "- Test Strategy.\n",
    "\n",
    "\n",
    "## 3.2.1 Performance Measure\n",
    "The observations are a count of champagne sales in millions of units.\n",
    "\n",
    "We will evaluate the performance of predictions using the root mean squared error (RMSE). This will give more weight to predictions that are grossly wrong and will have the same units as the original data.\n",
    "\n",
    "Any transforms to the data must be reversed before the RMSE is calculated and reported to make the performance between different methods directly comparable.\n",
    "\n",
    "We can calculate the RMSE using the helper function from the scikit-learn library mean_squared_error() that calculates the mean squared error between a list of expected values (the test set) and the list of predictions. We can then take the square root of this value to give us an RMSE score.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# ...\n",
    "test = ...\n",
    "predictions = ...\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)\n",
    "```\n",
    "\n",
    "## 3.2.2 Test Strategy\n",
    "Candidate models will be evaluated using walk-forward validation.\n",
    "\n",
    "This is because a rolling-forecast type model is required from the problem definition. This is where one-step forecasts are needed given all available data.\n",
    "\n",
    "The walk-forward validation will work as follows:\n",
    "\n",
    "The first 50% of the dataset will be held back to train the model.\n",
    "The remaining 50% of the dataset will be iterated and test the model.\n",
    "\n",
    "For each step in the test dataset:\n",
    "A model will be trained.\n",
    "A one-step prediction made and the prediction stored for later evaluation.\n",
    "The actual observation from the test dataset will be added to the training dataset for the next iteration.\n",
    "The predictions made during the iteration of the test dataset will be evaluated and an RMSE score reported.\n",
    "Given the small size of the data, we will allow a model to be re-trained given all available data prior to each prediction.\n",
    "\n",
    "We can write the code for the test harness using simple NumPy and Python code.\n",
    "\n",
    "Firstly, we can split the dataset into train and test sets directly. We’re careful to always convert a loaded dataset to float32 in case the loaded data still has some String or Integer data types.\n",
    "\n",
    "# prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we can iterate over the time steps in the test dataset. The train dataset is stored in a Python list as we need to easily append a new observation each iteration and NumPy array concatenation feels like overkill.\n",
    "\n",
    "The prediction made by the model is called yhat for convention, as the outcome or observation is referred to as y and yhat (a ‘y‘ with a mark above) is the mathematical notation for the prediction of the y variable.\n",
    "\n",
    "The prediction and observation are printed each observation for a sanity check prediction in case there are issues with the model.\n",
    "\n",
    "# walk-forward validation\n",
    "\n",
    "```python\n",
    "test = []\n",
    "train = []\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "\t# predict\n",
    "\tyhat = ...\n",
    "\tpredictions.append(yhat)\n",
    "\t# observation\n",
    "\tobs = test[i]\n",
    "\thistory.append(obs)\n",
    "\tprint('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "```\n",
    "\n",
    "## 4. Persistence\n",
    "\n",
    "The first step before getting bogged down in data analysis and modeling is to establish a baseline of performance.\n",
    "\n",
    "This will provide both a template for evaluating models using the proposed test harness and a performance measure by which all more elaborate predictive models can be compared.\n",
    "\n",
    "The baseline prediction for time series forecasting is called the naive forecast, or persistence.\n",
    "\n",
    "This is where the observation from the previous time step is used as the prediction for the observation at the next time step.\n",
    "\n",
    "We can plug this directly into the test harness defined in the previous section.\n",
    "\n",
    "The complete code listing is provided below.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# load data\n",
    "series = Series.from_csv('dataset.csv')\n",
    "\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "\t# predict\n",
    "\tyhat = history[-1]\n",
    "\tpredictions.append(yhat)\n",
    "\t# observation\n",
    "\tobs = test[i]\n",
    "\thistory.append(obs)\n",
    "\tprint('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "\n",
    "# report performance\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the test harness prints the prediction and observation for each iteration of the test dataset.\n",
    "\n",
    "The example ends by printing the RMSE for the model.\n",
    "\n",
    "In this case, we can see that the persistence model achieved an RMSE of 3186.501. This means that on average, the model was wrong by about 3,186 million sales for each prediction made.\n",
    "\n",
    "We now have a baseline prediction method and performance; now we can start digging into our data.\n",
    "\n",
    "## 5. Data Analysis\n",
    "We can use summary statistics and plots of the data to quickly learn more about the structure of the prediction problem.\n",
    "\n",
    "In this section, we will look at the data from five perspectives:\n",
    "\n",
    "- Summary Statistics.\n",
    "- Line Plot.\n",
    "- Seasonal Line Plots\n",
    "- Density Plots.\n",
    "- Box and Whisker Plot.\n",
    "\n",
    "\n",
    "## 5.1 Summary Statistics\n",
    "Summary statistics provide a quick look at the limits of observed values. It can help to get a quick idea of what we are working with.\n",
    "\n",
    "The example below calculates and prints summary statistics for the time series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "series = Series.from_csv('dataset.csv')\n",
    "print(series.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example provides a number of summary statistics to review.\n",
    "\n",
    "Some observations from these statistics include:\n",
    "\n",
    "The number of observations (count) matches our expectation, meaning we are handling the data correctly.\n",
    "The mean is about 4,641, which we might consider our level in this series.\n",
    "The standard deviation (average spread from the mean) is relatively large at 2,486 sales.\n",
    "The percentiles along with the standard deviation do suggest a large spread to the data.\n",
    "\n",
    "count       93.000000\n",
    "mean      4641.118280\n",
    "std       2486.403841\n",
    "min       1573.000000\n",
    "25%       3036.000000\n",
    "50%       4016.000000\n",
    "75%       5048.000000\n",
    "max      13916.000000\n",
    "\n",
    "\n",
    "## 5.2 Line Plot\n",
    "A line plot of a time series can provide a lot of insight into the problem.\n",
    "\n",
    "The example below creates and shows a line plot of the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "series = Series.from_csv('dataset.csv')\n",
    "series.plot()\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the example and review the plot. Note any obvious temporal structures in the series.\n",
    "\n",
    "Some observations from the plot include:\n",
    "\n",
    "- There may be an increasing trend of sales over time.\n",
    "- There appears to be systematic seasonality to the sales for each year.\n",
    "- The seasonal signal appears to be growing over time, suggesting a multiplicative relationship (increasing change).\n",
    "- There do not appear to be any obvious outliers.\n",
    "- The seasonality suggests that the series is almost certainly non-stationary.\n",
    "- Champagne Sales Line Plot\n",
    "\n",
    "\n",
    "There may be benefit in explicitly modeling the seasonal component and removing it. You may also explore using differencing with one or two levels in order to make the series stationary.\n",
    "\n",
    "The increasing trend or growth in the seasonal component may suggest the use of a log or other power transform.\n",
    "\n",
    "## 5.3 Seasonal Line Plots\n",
    "We can confirm the assumption that the seasonality is a yearly cycle by eyeballing line plots of the dataset by year.\n",
    "\n",
    "The example below takes the 7 full years of data as separate groups and creates one line plot for each. The line plots are aligned vertically to help spot any year-to-year pattern."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from pandas import TimeGrouper\n",
    "from matplotlib import pyplot\n",
    "series = Series.from_csv('dataset.csv')\n",
    "groups = series['1964':'1970'].groupby(TimeGrouper('A'))\n",
    "years = DataFrame()\n",
    "pyplot.figure()\n",
    "i = 1\n",
    "n_groups = len(groups)\n",
    "for name, group in groups:\n",
    "\tpyplot.subplot((n_groups*100) + 10 + i)\n",
    "\ti += 1\n",
    "\tpyplot.plot(group)\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example creates the stack of 7 line plots.\n",
    "\n",
    "We can clearly see a dip each August and a rise from each August to December. This pattern appears the same each year, although at different levels.\n",
    "\n",
    "This will help with any explicitly season-based modeling later.\n",
    "\n",
    "It might have been easier if all season line plots were added to the one graph to help contrast the data for each year.\n",
    "\n",
    "## 5.4 Density Plot\n",
    "Reviewing plots of the density of observations can provide further insight into the structure of the data.\n",
    "\n",
    "The example below creates a histogram and density plot of the observations without any temporal structure."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "series = Series.from_csv('dataset.csv')\n",
    "pyplot.figure(1)\n",
    "pyplot.subplot(211)\n",
    "series.hist()\n",
    "pyplot.subplot(212)\n",
    "series.plot(kind='kde')\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Run the example and review the plots.\n",
    "\n",
    "Some observations from the plots include:\n",
    "\n",
    "- The distribution is not Gaussian.\n",
    "- The shape has a long right tail and may suggest an exponential distribution\n",
    "\n",
    "This lends more support to exploring some power transforms of the data prior to modeling.\n",
    "\n",
    "## 5.5 Box and Whisker Plots\n",
    "We can group the monthly data by year and get an idea of the spread of observations for each year and how this may be changing.\n",
    "\n",
    "We do expect to see some trend (increasing mean or median), but it may be interesting to see how the rest of the distribution may be changing.\n",
    "\n",
    "The example below groups the observations by year and creates one box and whisker plot for each year of observations. The last year (1971) only contains 9 months and may not be a useful comparison with the 12 months of observations for other years. Therefore, only data between 1964 and 1970 was plotted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from pandas import TimeGrouper\n",
    "from matplotlib import pyplot\n",
    "series = Series.from_csv('dataset.csv')\n",
    "groups = series['1964':'1970'].groupby(TimeGrouper('A'))\n",
    "years = DataFrame()\n",
    "for name, group in groups:\n",
    "\tyears[name.year] = group.values\n",
    "years.boxplot()\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example creates 7 box and whisker plots side-by-side, one for each of the 7 years of selected data.\n",
    "\n",
    "Some observations from reviewing the plots include:\n",
    "\n",
    "- The median values for each year (red line) may show an increasing trend.\n",
    "- The spread or middle 50% of the data (blue boxes) does appear reasonably stable.\n",
    "- There are outliers each year (black crosses); these may be the tops or bottoms of the seasonal cycle.\n",
    "- The last year, 1970, does look different from the trend in prior years\n",
    "- Champagne Sales Box and Whisker Plots\n",
    "- Champagne Sales Box and Whisker Plots\n",
    "\n",
    "The observations suggest perhaps some growth trend over the years and outliers that may be a part of the seasonal cycle.\n",
    "\n",
    "This yearly view of the data is an interesting avenue and could be pursued further by looking at summary statistics from year-to-year and changes in summary stats from year-to-year.\n",
    "\n",
    "## 6. ARIMA Models\n",
    "In this section, we will develop Autoregressive Integrated Moving Average, or ARIMA, models for the problem.\n",
    "\n",
    "We will approach modeling by both manual and automatic configuration of the ARIMA model. This will be followed by a third step of investigating the residual errors of the chosen model.\n",
    "\n",
    "As such, this section is broken down into 3 steps:\n",
    "\n",
    "- Manually Configure the ARIMA.\n",
    "- Automatically Configure the ARIMA.\n",
    "- Review Residual Errors.\n",
    "\n",
    "\n",
    "## 6.1 Manually Configured ARIMA\n",
    "\n",
    "The ARIMA(p,d,q) model requires three parameters and is traditionally configured manually.\n",
    "\n",
    "Analysis of the time series data assumes that we are working with a stationary time series.\n",
    "\n",
    "The time series is almost certainly non-stationary. We can make it stationary this by first differencing the series and using a statistical test to confirm that the result is stationary.\n",
    "\n",
    "The seasonality in the series is seemingly year-to-year. Seasonal data can be differenced by subtracting the observation from the same time in the previous cycle, in this case the same month in the previous year. This does mean that we will lose the first year of observations as there is no prior year to difference with.\n",
    "\n",
    "The example below creates a deseasonalized version of the series and saves it to file stationary.csv.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "series = Series.from_csv('dataset.csv')\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "\n",
    "# difference data\n",
    "months_in_year = 12\n",
    "stationary = difference(X, months_in_year)\n",
    "stationary.index = series.index[months_in_year:]\n",
    "\n",
    "# check if stationary\n",
    "result = adfuller(stationary)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "# save\n",
    "stationary.to_csv('stationary.csv')\n",
    "\n",
    "# plot\n",
    "stationary.plot()\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example outputs the result of a statistical significance test of whether the differenced series is stationary. Specifically, the augmented Dickey-Fuller test.\n",
    "\n",
    "The results show that the test statistic value -7.134898 is smaller than the critical value at 1% of -3.515. This suggests that we can reject the null hypothesis with a significance level of less than 1% (i.e. a low probability that the result is a statistical fluke).\n",
    "\n",
    "Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure.\n",
    "\n",
    "ADF Statistic: -7.134898\n",
    "p-value: 0.000000\n",
    "Critical Values:\n",
    "\t5%: -2.898\n",
    "\t1%: -3.515\n",
    "\t10%: -2.586\n",
    "\n",
    "\n",
    "For reference, the seasonal difference operation can be inverted by adding the observation for the same month the year before. This is needed in the case that predictions are made by a model fit on seasonally differenced data. The function to invert the seasonal difference operation is listed below for completeness.\n",
    "\n",
    "# invert differenced value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A plot of the differenced dataset is also created.\n",
    "\n",
    "The plot does not show any obvious seasonality or trend, suggesting the seasonally differenced dataset is a good starting point for modeling.\n",
    "\n",
    "We will use this dataset as an input to the ARIMA model. It also suggests that no further differencing may be required, and that the d parameter may be set to 0.\n",
    "\n",
    "### Seasonal Differenced Champagne Sales Line Plot\n",
    "\n",
    "The next first step is to select the lag values for the Autoregression (AR) and Moving Average (MA) parameters, p and q respectively.\n",
    "\n",
    "We can do this by reviewing Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots.\n",
    "\n",
    "Note, we are now using the seasonally differenced stationary.csv as our dataset.\n",
    "\n",
    "The example below creates ACF and PACF plots for the series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib import pyplot\n",
    "\n",
    "series = Series.from_csv('stationary.csv')\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.subplot(211)\n",
    "\n",
    "plot_acf(series, ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "\n",
    "plot_pacf(series, ax=pyplot.gca())\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the example and review the plots for insights into how to set the p and q variables for the ARIMA model.\n",
    "\n",
    "Below are some observations from the plots.\n",
    "\n",
    "- The ACF shows a significant lag for 1 month.\n",
    "- The PACF shows a significant lag for 1 month, with perhaps some significant lag at 12 and 13 months.\n",
    "- Both the ACF and PACF show a drop-off at the same point, perhaps suggesting a mix of AR and MA.\n",
    "- A good starting point for the p and q values is also 1.\n",
    "\n",
    "The PACF plot also suggests that there is still some seasonality present in the differenced data.\n",
    "\n",
    "We may consider a better model of seasonality, such as modeling it directly and explicitly removing it from the model rather than seasonal differencing.\n",
    "\n",
    "### ACF and PACF Plots of Seasonally Differenced Champagne Sales\n",
    "\n",
    "This quick analysis suggests an ARIMA(1,0,1) on the stationary data may be a good starting point.\n",
    "\n",
    "The historic observations will be seasonally differenced prior to the fitting of each ARIMA model. The differencing will be inverted for all predictions made to make them directly comparable to the expected observation in the original sale count units.\n",
    "\n",
    "Experimentation shows that this configuration of ARIMA does not converge and results in errors by the underlying library. Further experimentation showed that adding one level of differencing to the stationary data made the model more stable. The model can be extended to ARIMA(1,1,1).\n",
    "\n",
    "We will also disable the automatic addition of a trend constant from the model by setting the ‘trend‘ argument to ‘nc‘ for no constant in the call to fit(). From experimentation, I find that this can result in better forecast performance on some problems.\n",
    "\n",
    "The example below demonstrates the performance of this ARIMA model on the test harness."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn diff\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# load data\n",
    "series = Series.from_csv('dataset.csv')\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "\t# difference data\n",
    "\tmonths_in_year = 12\n",
    "\tdiff = difference(history, months_in_year)\n",
    "\t# predict\n",
    "\tmodel = ARIMA(diff, order=(1,1,1))\n",
    "\tmodel_fit = model.fit(trend='nc', disp=0)\n",
    "\tyhat = model_fit.forecast()[0]\n",
    "\tyhat = inverse_difference(history, yhat, months_in_year)\n",
    "\tpredictions.append(yhat)\n",
    "\t# observation\n",
    "\tobs = test[i]\n",
    "\thistory.append(obs)\n",
    "\tprint('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "# report performance\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note, you may see a warning message from the underlying linear algebra library; this can be ignored for now.\n",
    "\n",
    "Running this example results in an RMSE of 956.942, which is dramatically better than the persistence RMSE of 3186.501.\n",
    "\n",
    "...\n",
    ">Predicted=3157.018, Expected=5010\n",
    ">Predicted=4615.082, Expected=4874\n",
    ">Predicted=4624.998, Expected=4633\n",
    ">Predicted=2044.097, Expected=1659\n",
    ">Predicted=5404.428, Expected=5951\n",
    "\n",
    "This is a great start, but we may be able to get improved results with a better configured ARIMA model.\n",
    "\n",
    "## 6.2 Grid Search ARIMA Hyperparameters\n",
    "The ACF and PACF plots suggest that an ARIMA(1,0,1) or similar may be the best that we can do.\n",
    "\n",
    "To confirm this analysis, we can grid search a suite of ARIMA hyperparameters and check that no models result in better out of sample RMSE performance.\n",
    "\n",
    "In this section, we will search values of p, d, and q for combinations (skipping those that fail to converge), and find the combination that results in the best performance on the test set. We will use a grid search to explore all combinations in a subset of integer values.\n",
    "\n",
    "Specifically, we will search all combinations of the following parameters:\n",
    "\n",
    "p: 0 to 6.\n",
    "d: 0 to 2.\n",
    "q: 0 to 6.\n",
    "This is (7 * 3 * 7), or 147, potential runs of the test harness and will take some time to execute.\n",
    "\n",
    "It may be interesting to evaluate MA models with a lag of 12 or 13 as were noticed as potentially interesting from reviewing the ACF and PACF plots. Experimentation suggested that these models may not be stable, resulting in errors in the underlying mathematical libraries.\n",
    "\n",
    "The complete worked example with the grid search version of the test harness is listed below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas import Series\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn numpy.array(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "\t# prepare training dataset\n",
    "\tX = X.astype('float32')\n",
    "\ttrain_size = int(len(X) * 0.50)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\thistory = [x for x in train]\n",
    "\t# make predictions\n",
    "\tpredictions = list()\n",
    "\tfor t in range(len(test)):\n",
    "\t\t# difference data\n",
    "\t\tmonths_in_year = 12\n",
    "\t\tdiff = difference(history, months_in_year)\n",
    "\t\tmodel = ARIMA(diff, order=arima_order)\n",
    "\t\tmodel_fit = model.fit(trend='nc', disp=0)\n",
    "\t\tyhat = model_fit.forecast()[0]\n",
    "\t\tyhat = inverse_difference(history, yhat, months_in_year)\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\thistory.append(test[t])\n",
    "\t# calculate out of sample error\n",
    "\tmse = mean_squared_error(test, predictions)\n",
    "\trmse = sqrt(mse)\n",
    "\treturn rmse\n",
    "\n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "\tdataset = dataset.astype('float32')\n",
    "\tbest_score, best_cfg = float(\"inf\"), None\n",
    "\tfor p in p_values:\n",
    "\t\tfor d in d_values:\n",
    "\t\t\tfor q in q_values:\n",
    "\t\t\t\torder = (p,d,q)\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tmse = evaluate_arima_model(dataset, order)\n",
    "\t\t\t\t\tif mse < best_score:\n",
    "\t\t\t\t\t\tbest_score, best_cfg = mse, order\n",
    "\t\t\t\t\tprint('ARIMA%s RMSE=%.3f' % (order,mse))\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tcontinue\n",
    "\tprint('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n",
    "\n",
    "# load dataset\n",
    "series = Series.from_csv('dataset.csv')\n",
    "# evaluate parameters\n",
    "p_values = range(0, 7)\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 7)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(series.values, p_values, d_values, q_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example runs through all combinations and reports the results on those that converge without error. The example takes a little over 2 minutes to run on modern hardware.\n",
    "\n",
    "The results show that the best configuration discovered was ARIMA(0, 0, 1) with an RMSE of 939.464, slightly lower than the manually configured ARIMA from the previous section. This difference may or may not be statistically significant.\n",
    "\n",
    "...\n",
    "ARIMA(5, 1, 2) RMSE=1003.200\n",
    "ARIMA(5, 2, 1) RMSE=1053.728\n",
    "ARIMA(6, 0, 0) RMSE=996.466\n",
    "ARIMA(6, 1, 0) RMSE=1018.211\n",
    "ARIMA(6, 1, 1) RMSE=1023.762\n",
    "Best ARIMA(0, 0, 1) RMSE=939.464\n",
    "\n",
    "\n",
    "We will select this ARIMA(0, 0, 1) model going forward.\n",
    "\n",
    "## 6.3 Review Residual Errors\n",
    "A good final check of a model is to review residual forecast errors.\n",
    "\n",
    "Ideally, the distribution of residual errors should be a Gaussian with a zero mean.\n",
    "\n",
    "We can check this by using summary statistics and plots to investigate the residual errors from the ARIMA(0, 0, 1) model. The example below calculates and summarizes the residual forecast errors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn diff\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# load data\n",
    "series = Series.from_csv('dataset.csv')\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "\t# difference data\n",
    "\tmonths_in_year = 12\n",
    "\tdiff = difference(history, months_in_year)\n",
    "\t# predict\n",
    "\tmodel = ARIMA(diff, order=(0,0,1))\n",
    "\tmodel_fit = model.fit(trend='nc', disp=0)\n",
    "\tyhat = model_fit.forecast()[0]\n",
    "\tyhat = inverse_difference(history, yhat, months_in_year)\n",
    "\tpredictions.append(yhat)\n",
    "\t# observation\n",
    "\tobs = test[i]\n",
    "\thistory.append(obs)\n",
    "# errors\n",
    "residuals = [test[i]-predictions[i] for i in range(len(test))]\n",
    "residuals = DataFrame(residuals)\n",
    "print(residuals.describe())\n",
    "# plot\n",
    "pyplot.figure()\n",
    "pyplot.subplot(211)\n",
    "residuals.hist(ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "residuals.plot(kind='kde', ax=pyplot.gca())\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example first describes the distribution of the residuals.\n",
    "\n",
    "We can see that the distribution has a right shift and that the mean is non-zero at 165.904728.\n",
    "\n",
    "This is perhaps a sign that the predictions are biased.\n",
    "\n",
    "count    47.000000\n",
    "mean    165.904728\n",
    "std     934.696199\n",
    "min   -2164.247449\n",
    "25%    -289.651596\n",
    "50%     191.759548\n",
    "75%     732.992187\n",
    "max    2367.304748\n",
    "The distribution of residual errors is also plotted.\n",
    "\n",
    "The graphs suggest a Gaussian-like distribution with a bumpy left tail, providing further evidence that perhaps a power transform might be worth exploring.\n",
    "\n",
    "Residual Forecast Error Density Plots\n",
    "Residual Forecast Error Density Plots\n",
    "\n",
    "We could use this information to bias-correct predictions by adding the mean residual error of 165.904728 to each forecast made.\n",
    "\n",
    "The example below performs this bias correlation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn diff\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# load data\n",
    "series = Series.from_csv('dataset.csv')\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "bias = 165.904728\n",
    "for i in range(len(test)):\n",
    "\t# difference data\n",
    "\tmonths_in_year = 12\n",
    "\tdiff = difference(history, months_in_year)\n",
    "\t# predict\n",
    "\tmodel = ARIMA(diff, order=(0,0,1))\n",
    "\tmodel_fit = model.fit(trend='nc', disp=0)\n",
    "\tyhat = model_fit.forecast()[0]\n",
    "\tyhat = bias + inverse_difference(history, yhat, months_in_year)\n",
    "\tpredictions.append(yhat)\n",
    "\t# observation\n",
    "\tobs = test[i]\n",
    "\thistory.append(obs)\n",
    "# report performance\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)\n",
    "# errors\n",
    "residuals = [test[i]-predictions[i] for i in range(len(test))]\n",
    "residuals = DataFrame(residuals)\n",
    "print(residuals.describe())\n",
    "# plot\n",
    "pyplot.figure()\n",
    "pyplot.subplot(211)\n",
    "residuals.hist(ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "residuals.plot(kind='kde', ax=pyplot.gca())\n",
    "pyplot.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The performance of the predictions is improved very slightly from 939.464 to 924.699, which may or may not be significant.\n",
    "\n",
    "The summary of the forecast residual errors shows that the mean was indeed moved to a value very close to zero.\n",
    "\n",
    "RMSE: 924.699\n",
    "| Variable | Amount |\n",
    "| -- | -- |\n",
    "| count | 4.700000e+01 |\n",
    "| mean  | 4.965016e-07 |\n",
    "| std   | 9.346962e+02 |\n",
    "| min   |-2.330152e+03 |\n",
    "| 25%   |-4.555563e+02 |\n",
    "| 50%   | 2.585482e+01 |\n",
    "| 75%   | 5.670875e+02 |\n",
    "| max   | 2.201400e+03 |\n",
    "\n",
    "\n",
    "Finally, density plots of the residual error do show a small shift towards zero.\n",
    "\n",
    "It is debatable whether this bias correction is worth it, but we will use it for now.\n",
    "\n",
    "### Bias Corrected Residual Forecast Error Density Plots\n",
    "\n",
    "It is also a good idea to check the time series of the residual errors for any type of autocorrelation. If present, it would suggest that the model has more opportunity to model the temporal structure in the data.\n",
    "\n",
    "The example below re-calculates the residual errors and creates ACF and PACF plots to check for any significant autocorrelation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn diff\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# load data\n",
    "series = Series.from_csv('dataset.csv')\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "\t# difference data\n",
    "\tmonths_in_year = 12\n",
    "\tdiff = difference(history, months_in_year)\n",
    "\t# predict\n",
    "\tmodel = ARIMA(diff, order=(0,0,1))\n",
    "\tmodel_fit = model.fit(trend='nc', disp=0)\n",
    "\tyhat = model_fit.forecast()[0]\n",
    "\tyhat = inverse_difference(history, yhat, months_in_year)\n",
    "\tpredictions.append(yhat)\n",
    "\t# observation\n",
    "\tobs = test[i]\n",
    "\thistory.append(obs)\n",
    "# errors\n",
    "residuals = [test[i]-predictions[i] for i in range(len(test))]\n",
    "residuals = DataFrame(residuals)\n",
    "print(residuals.describe())\n",
    "# plot\n",
    "pyplot.figure()\n",
    "pyplot.subplot(211)\n",
    "plot_acf(residuals, ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "plot_pacf(residuals, ax=pyplot.gca())\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results suggest that what little autocorrelation is present in the time series has been captured by the model.\n",
    "\n",
    "\n",
    "Residual Forecast Error ACF and PACF Plots\n",
    "\n",
    "## 7. Model Validation\n",
    "After models have been developed and a final model selected, it must be validated and finalized.\n",
    "\n",
    "Validation is an optional part of the process, but one that provides a ‘last check’ to ensure we have not fooled or misled ourselves.\n",
    "\n",
    "This section includes the following steps:\n",
    "\n",
    "- Finalize Model: Train and save the final model.\n",
    "- Make Prediction: Load the finalized model and make a prediction.\n",
    "- Validate Model: Load and validate the final model.\n",
    "\n",
    "\n",
    "## 7.1 Finalize Model\n",
    "Finalizing the model involves fitting an ARIMA model on the entire dataset, in this case on a transformed version of the entire dataset.\n",
    "\n",
    "Once fit, the model can be saved to file for later use.\n",
    "\n",
    "The example below trains an ARIMA(0,0,1) model on the dataset and saves the whole fit object and the bias to file.\n",
    "\n",
    "There is a bug in the current stable version of the statsmodels library (v0.6.1) that results in an error when you try to load a saved ARIMA model from file. The error reported is:\n",
    "\n",
    "TypeError: __new__() takes at least 3 arguments (1 given)\n",
    "\n",
    "\n",
    "This bug also seems present in the 0.8 release candidate 1 of statsmodels when I tested it. For more details, see Zae Myung Kim‘s discussion and fix in this GitHub issue.\n",
    "\n",
    "We can work around this with a monkey patch that adds a __getnewargs__() instance function to the ARIMA class before saving.\n",
    "\n",
    "The example below saves the fit model to file in the correct state so that it can be loaded successfully later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from scipy.stats import boxcox\n",
    "import numpy\n",
    "\n",
    "# monkey patch around bug in ARIMA class\n",
    "def __getnewargs__(self):\n",
    "\treturn ((self.endog),(self.k_lags, self.k_diff, self.k_ma))\n",
    "\n",
    "ARIMA.__getnewargs__ = __getnewargs__\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn diff\n",
    "\n",
    "# load data\n",
    "series = Series.from_csv('dataset.csv')\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "# difference data\n",
    "months_in_year = 12\n",
    "diff = difference(X, months_in_year)\n",
    "# fit model\n",
    "model = ARIMA(diff, order=(0,0,1))\n",
    "model_fit = model.fit(trend='nc', disp=0)\n",
    "# bias constant, could be calculated from in-sample mean residual\n",
    "bias = 165.904728\n",
    "# save model\n",
    "model_fit.save('model.pkl')\n",
    "numpy.save('model_bias.npy', [bias])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example creates two local files:\n",
    "\n",
    "model.pkl This is the ARIMAResult object from the call to ARIMA.fit(). This includes the coefficients and all other internal data returned when fitting the model.\n",
    "model_bias.npy This is the bias value stored as a one-row, one-column NumPy array.\n",
    "\n",
    "\n",
    "## 7.2 Make Prediction\n",
    "A natural case may be to load the model and make a single forecast.\n",
    "\n",
    "This is relatively straightforward and involves restoring the saved model and the bias and calling the forecast() method. To invert the seasonal differencing, the historical data must also be loaded.\n",
    "\n",
    "The example below loads the model, makes a prediction for the next time step, and prints the prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from statsmodels.tsa.arima_model import ARIMAResults\n",
    "import numpy\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "series = Series.from_csv('dataset.csv')\n",
    "months_in_year = 12\n",
    "model_fit = ARIMAResults.load('model.pkl')\n",
    "bias = numpy.load('model_bias.npy')\n",
    "yhat = float(model_fit.forecast()[0])\n",
    "yhat = bias + inverse_difference(series.values, yhat, months_in_year)\n",
    "print('Predicted: %.3f' % yhat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example prints the prediction of about 6794.\n",
    "\n",
    "Predicted: 6794.773\n",
    "\n",
    "If we peek inside validation.csv, we can see that the value on the first row for the next time period is 6981.\n",
    "\n",
    "The prediction is in the right ballpark.\n",
    "\n",
    "## 7.3 Validate Model\n",
    "We can load the model and use it in a pretend operational manner.\n",
    "\n",
    "In the test harness section, we saved the final 12 months of the original dataset in a separate file to validate the final model.\n",
    "\n",
    "We can load this validation.csv file now and use it see how well our model really is on “unseen” data.\n",
    "\n",
    "There are two ways we might proceed:\n",
    "\n",
    "Load the model and use it to forecast the next 12 months. The forecast beyond the first one or two months will quickly start to degrade in skill.\n",
    "Load the model and use it in a rolling-forecast manner, updating the transform and model for each time step. This is the preferred method as it is how one would use this model in practice as it would achieve the best performance.\n",
    "As with model evaluation in previous sections, we will make predictions in a rolling-forecast manner. This means that we will step over lead times in the validation dataset and take the observations as an update to the history."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.arima_model import ARIMAResults\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn diff\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# load and prepare datasets\n",
    "dataset = Series.from_csv('dataset.csv')\n",
    "X = dataset.values.astype('float32')\n",
    "history = [x for x in X]\n",
    "months_in_year = 12\n",
    "validation = Series.from_csv('validation.csv')\n",
    "y = validation.values.astype('float32')\n",
    "# load model\n",
    "model_fit = ARIMAResults.load('model.pkl')\n",
    "bias = numpy.load('model_bias.npy')\n",
    "# make first prediction\n",
    "predictions = list()\n",
    "yhat = float(model_fit.forecast()[0])\n",
    "yhat = bias + inverse_difference(history, yhat, months_in_year)\n",
    "predictions.append(yhat)\n",
    "history.append(y[0])\n",
    "print('>Predicted=%.3f, Expected=%3.f' % (yhat, y[0]))\n",
    "# rolling forecasts\n",
    "for i in range(1, len(y)):\n",
    "\t# difference data\n",
    "\tmonths_in_year = 12\n",
    "\tdiff = difference(history, months_in_year)\n",
    "\t# predict\n",
    "\tmodel = ARIMA(diff, order=(0,0,1))\n",
    "\tmodel_fit = model.fit(trend='nc', disp=0)\n",
    "\tyhat = model_fit.forecast()[0]\n",
    "\tyhat = bias + inverse_difference(history, yhat, months_in_year)\n",
    "\tpredictions.append(yhat)\n",
    "\t# observation\n",
    "\tobs = y[i]\n",
    "\thistory.append(obs)\n",
    "\tprint('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "# report performance\n",
    "mse = mean_squared_error(y, predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)\n",
    "pyplot.plot(y)\n",
    "pyplot.plot(predictions, color='red')\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the example prints each prediction and expected value for the time steps in the validation dataset.\n",
    "\n",
    "The final RMSE for the validation period is predicted at 361.110 million sales.\n",
    "\n",
    "This is much better than the expectation of an error of a little more than 924 million sales per month.\n",
    "\n",
    ">Predicted=6794.773, Expected=6981\n",
    ">Predicted=10101.763, Expected=9851\n",
    ">Predicted=13219.067, Expected=12670\n",
    ">Predicted=3996.535, Expected=4348\n",
    ">Predicted=3465.934, Expected=3564\n",
    ">Predicted=4522.683, Expected=4577\n",
    ">Predicted=4901.336, Expected=4788\n",
    ">Predicted=5190.094, Expected=4618\n",
    ">Predicted=4930.190, Expected=5312\n",
    ">Predicted=4944.785, Expected=4298\n",
    ">Predicted=1699.409, Expected=1413\n",
    ">Predicted=6085.324, Expected=5877\n",
    "RMSE: 361.110\n",
    "\n",
    "A plot of the predictions compared to the validation dataset is also provided.\n",
    "\n",
    "At this scale on the plot, the 12 months of forecast sales figures look fantastic.\n",
    "\n",
    "\n",
    "## Summary\n",
    "In this tutorial, you discovered the steps and the tools for a time series forecasting project with Python.\n",
    "\n",
    "We have covered a lot of ground in this tutorial; specifically:\n",
    "\n",
    "How to develop a test harness with a performance measure and evaluation method and how to quickly develop a baseline forecast and skill.\n",
    "How to use time series analysis to raise ideas for how to best model the forecast problem.\n",
    "How to develop an ARIMA model, save it, and later load it to make predictions on new data.\n",
    "How did you do? Do you have any questions about this tutorial?\n",
    "Ask your questions in the comments below and I will do my best to answer."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}